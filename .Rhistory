article_urls <- data.frame()
### If you do not have one: you can make one for free here: https://developer.nytimes.com/get-started
### This key will work, but you should make your own because there is a non 0 chance
### that my key won't have any uses when you attempt to run this
key <- "yKfZ0OFrJ1Yv7EnALtHTS6OTNnFgFFqR"
version
candidate <- c("Richard+Nixon", "Hubert+Humphrey",
"Richard+Nixon", "George+McGovern",
"Jimmy+Carter", "Gerald+Ford",
"Ronald+Reagan", "Jimmy+Carter",
"Ronald+Reagan", "Walter+Mondale",
"George+Bush", "Michael+Dukakis",
"Bill+Clinton", "George+Bush",
"Bill+Clinton", "Bob+Dole",
"George+W.+Bush", "Al+Gore",
"George+W.+Bush", "John+Kerry",
"Barack+Obama", "John+McCain",
"Barack+Obama", "Mitt+Romney",
"Donald+Trump", "Hillary+Clinton",
"Joseph+Biden", "Donald+Trump",
"Donald+Trump", "Kamala+Harris")
incumbant_party <- c(FALSE, TRUE,
TRUE, FALSE,
FALSE, TRUE,
FALSE, TRUE,
TRUE, FALSE,
TRUE, FALSE,
FALSE, TRUE,
TRUE,FALSE,
FALSE, TRUE,
TRUE,FALSE,
FALSE, TRUE,
TRUE, FALSE,
FALSE, TRUE,
FALSE, TRUE,
FALSE, TRUE)
party <- c("r", "d",
"r", "d",
"d", "r",
"r", "d",
"r", "d",
"r", "d",
"d", "r",
"d", "r",
"r", "d",
"r", "d",
"d", "r",
"d", "r",
"r", "d",
"d", "r",
"r","d")
winner <- rep(c(TRUE, FALSE), 15)
### Create List of year
year <- c(rep(1968, 2), rep(1972, 2), rep(1976, 2), rep(1980, 2), rep(1984, 2),
rep(1988, 2), rep(1992, 2), rep(1996, 2), rep(2000, 2), rep(2004, 2),
rep(2008, 2), rep(2012, 2), rep(2016, 2), rep(2020, 2), rep(2024, 2))
### Create List Of Election Days in Year
election_day <- c(rep(ymd("1968-11-05"), 2), rep(ymd("1972-11-07"), 2), rep(ymd("1976-11-02"), 2),
rep(ymd("1980-11-04"), 2), rep(ymd("1984-11-06"), 2), rep(ymd("1988-11-08"), 2),
rep(ymd("1992-11-03"), 2), rep(ymd("1996-11-05"), 2), rep(ymd("2000-11-07"), 2),
rep(ymd("2004-11-02"), 2), rep(ymd("2008-11-04"), 2), rep(ymd("2012-11-06"), 2),
rep(ymd("2016-11-08"), 2), rep(ymd("2020-11-03"), 2), rep(ymd("2024-11-05"), 2))
### Combine These Lists into a dataframe
presidential_candidates <- data.frame(candidate = candidate, party = party, incumbant_party = incumbant_party, winner = winner, year = year, election_day = election_day)
### Create Column of Dates that are 107 days before election day (when Harris officially started running)
presidential_candidates <- presidential_candidates |> mutate(
start_date_2024_adjustment = election_day - days(107)
)
library(tidyverse)
library(lubridate)
library(httr)
library(rvest)
library(jsonlite)
### Create Column of Dates that are 107 days before election day (when Harris officially started running)
presidential_candidates <- presidential_candidates |> mutate(
start_date_2024_adjustment = election_day - days(107)
)
### Combine These Lists into a dataframe
presidential_candidates <- data.frame(candidate = candidate, party = party, incumbant_party = incumbant_party, winner = winner, year = year, election_day = election_day)
### Create List Of Election Days in Year
election_day <- c(rep(ymd("1968-11-05"), 2), rep(ymd("1972-11-07"), 2), rep(ymd("1976-11-02"), 2),
rep(ymd("1980-11-04"), 2), rep(ymd("1984-11-06"), 2), rep(ymd("1988-11-08"), 2),
rep(ymd("1992-11-03"), 2), rep(ymd("1996-11-05"), 2), rep(ymd("2000-11-07"), 2),
rep(ymd("2004-11-02"), 2), rep(ymd("2008-11-04"), 2), rep(ymd("2012-11-06"), 2),
rep(ymd("2016-11-08"), 2), rep(ymd("2020-11-03"), 2), rep(ymd("2024-11-05"), 2))
### Combine These Lists into a dataframe
presidential_candidates <- data.frame(candidate = candidate, party = party, incumbant_party = incumbant_party, winner = winner, year = year, election_day = election_day)
### Create Column of Dates that are 107 days before election day (when Harris officially started running)
presidential_candidates <- presidential_candidates |> mutate(
start_date_2024_adjustment = election_day - days(107)
)
### The For Loop to get Article URLs and publication dates from NYT API
for (i in 1:30) {
### Set Candidate Name
name <- presidential_candidates$candidate[[i]]
### Set Start Date 0 is for formatting date as YYYYMMDD the issue with this
### set of dates is the month number
start_date <- paste0(year(presidential_candidates$start_date_2024_adjustment[[i]]), "0",
month(presidential_candidates$start_date_2024_adjustment[[i]]),
day(presidential_candidates$start_date_2024_adjustment[[i]]))
### Set End Date 0 is for formatting date as YYYYMMDD The issue with this
### set of dates is the Day number
end_date <- paste0(year(presidential_candidates$election_day[[i]]),
month(presidential_candidates$election_day[[i]]), "0",
day(presidential_candidates$election_day[[i]]))
### Set Year
article_year <- presidential_candidates$year[[i]]
### Before 1984, all articles are classified as "archive" and not to their
### specific "news_desk" type.
if(article_year <= 1980) {
nyt_url <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?q=",name,
"&begin_date=",start_date,"&end_date=",end_date, "&sort=newest",
"&facet_filter=true&api-key=", key, sep="")
### Get First 100 Articles Sorted by Newest
for (g in 1:10) {
### Get Results
nytSearchResults <- fromJSON(paste0(nyt_url, "&page=", g), flatten = TRUE) %>% data.frame()
### Print Message Saying it was successful
print(paste0("Retrieved Results from Page ", g,
" On Articles Covering ", name, " in ", article_year))
### Select desired rows and add presidential information
nytSearchResults <- nytSearchResults |>
rename(web_url = response.docs.web_url,
pub_date = response.docs.pub_date) |>
select(c(web_url, pub_date)) |>
mutate(
candidate = name,
year = article_year
)
### Rbind with article_urls dataframe
article_urls <- rbind(article_urls, nytSearchResults)
### Sleep for 13 Seconds to allow for Maximum pulling of information
### I know that it is 12 seconds for the fastest possible, but I don't
### want to risk it breaking while I am asleep.
Sys.sleep(13)
}
}
### 1984 allows us to select for specifically opinion pieces
if (article_year >= 1984) {
### Set API Search
### I used their tool to help generate the correct URL for me to use
### https://developer.nytimes.com/docs/articlesearch-product/1/routes/articlesearch.json/get
### URL Filters Articles Based On Source, Section, and Document Type
### Section selects for Opinion and document type selects for articles
### rather than videos, slideshows, or other forms of interactive media.
nyt_url <- paste0("http://api.nytimes.com/svc/search/v2/articlesearch.json?q=",name,
"&begin_date=",start_date,"&end_date=",end_date, "&sort=newest",
"&fq=source%3A(%22The%20New%20York%20Times%22)%20AND%20document_type%3A(%22article%22)%20AND%20section_name%3A(%22Opinion%22)",
"&facet_filter=true&api-key=", key, sep="")
### Get First 100 Articles Sorted by Relevance
for (h in 1:10) {
### Get Results
nytSearchResults <- fromJSON(paste0(nyt_url, "&page=", h), flatten = TRUE) %>% data.frame()
### Print Message Saying it was successful
print(paste0("Retrieved Results from Page ", h,
" On Articles Covering ", name, " in ", article_year))
### Select desired rows and add presidential information
nytSearchResults <- nytSearchResults |>
rename(web_url = response.docs.web_url,
pub_date = response.docs.pub_date) |>
select(c(web_url, pub_date)) |>
mutate(
candidate = name,
year = article_year
)
### Rbind with article_urls dataframe
article_urls <- rbind(article_urls, nytSearchResults)
### Sleep for 13 Seconds to allow for Maximum pulling of information
### I know that it is 12 seconds for the fastest possible, but I don't
### want to risk it breaking while I am asleep.
Sys.sleep(13)
}
}
}
path <- "C:/Users/zades/Documents/GitHub/Final-Project/"
polling_data <- read.csv(paste0(path, "polling_data.csv"))
election_data <- read.csv(paste0(path, "vote_share_data.csv"))
sentiment_afinn <- read.csv(paste0(path, "sentiment_afinn.csv"))
sentiment_bing <- read.csv(paste0(path, "sentiment_bing.csv"))
polling_data <- polling_data |> select(!X)
election_data <- election_data |> select(!X)
sentiment_afinn <- sentiment_afinn |> select(!X)
sentiment_bing <- sentiment_bing |> select(!X)
###################
# Join Dataframes #
###################
model_dataset <- polling_data |> left_join(election_data, by = c("party", "year", "state"))
model_dataset <- model_dataset |> left_join(sentiment_afinn, by = c("candidate", "date", "year")) |>
left_join(sentiment_bing, by = c("candidate", "date", "year"))
###################################################
# Create Difference between prediction and result #
# Also, set vote_share And dem_margin to be on    #
# 100point scale                                  #
###################################################
model_dataset <- model_dataset |> relocate(pct_estimate, .before = vote_share) |>
mutate(
vote_share = vote_share*100,
dem_margin = dem_margin*100,
polling_difference = abs(vote_share - pct_estimate)
)
### Create Difference in margins
model_dataset <- model_dataset |>
mutate(margin_error = abs(dem_margin_estimate - dem_margin))
### Make Dates Date Times
model_dataset <- model_dataset |>
mutate(
date = ymd(date)
) |>
select(!election_day & !start_date_2024_adjustment)
### Set True False to 1 and 0 respectively
model_dataset <- model_dataset |>
mutate(incumbant_party = ifelse(incumbant_party == TRUE, 1, 0),
winner = ifelse(winner == TRUE, 1, 0))
### Write Necessary Dataframes to Disk
write.csv(model_dataset, paste0(path, "model_dataset.csv"))
### I decide to go with minimal controls to avoid overfitting
### control for year to adjust for polling methods changing and
### incumbancy party to control for incumbancy effects
### Also including states might be rising N too high with too little
### real variation (alot of earlier dates didn't have as many polls being done)
##########################################################
# Filter model dataset to only national level and redo   #
# previous regressions                                   #
##########################################################
national_data <- model_dataset |>
filter(state == "National")
write.csv(national_data, paste0(path, "national_data.csv"))
shiny::runApp('final-project-app')
